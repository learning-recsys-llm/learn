
# 推荐入门资料

[https://github.com/datawhalechina/fun-rec](https://github.com/datawhalechina/fun-rec)

对应的网站：[https://datawhalechina.github.io/fun-rec/#/](https://datawhalechina.github.io/fun-rec/#/)

[https://github.com/shenweichen/DeepCTR](https://github.com/shenweichen/DeepCTR)

# 推荐中的常见问题

## 什么是离线auc、在线auc

+ 离线auc：训练时的auc，一般训练分成如下两个阶段，离线训练时，流式auc=流式训阶段：
    + 离线：过去n天的数据上训的，所以离线auc就是这个阶段模型预估分和当时的真实label的auc
    + 流式：和样本的拼接窗口有关，例如拼接窗口是30min，就是比如7点进的直播间，等到7点30才产出训练数据，而真正给到模型去训练可能又会有一些延迟，比如7点35分模型才能见到这个样本。流式auc就是这个阶段模型预估分和当时的真实label的auc
+ 在线auc：在线请求时，根据预估分和真实label算的auc。比如现在是8点，用的可能是7点的数据训的模型，然后看这个模型精排预估分，和真实label的auc

两者的核心区别在于：

+ 离线auc：是训练阶段的auc，一般会比较高，因为模型就是在这些样本上训练的
+ 在线auc：是在线服务阶段的auc，是针对新来的样本的预估，也就是说这些样本模型没见过，所以一般会低一点

## 为什么有时候auc涨了，在线却没收益

一般常见的可能原因：

+ 特征引起的在离线逻辑不一致：例如加特征了，可能在线的处理逻辑和训练时的处理逻辑是两套代码，或者数据源不一样（比如有个特征，离线是读的hive表，在线是读的某个存储序列的服务，可能二者本身的内容就不太一样），会出现不一致
+ 模型出现lag（延迟）：即本来7点就能训好的模型，可能因为机器资源不够，到10点才训好，那说明在10点的时候，模型只见过7点前的样本，没见过8点和9点的样本，肯定效果不好
+ 这个模型确实没啥用：例如后面有很多奇怪的boost操作，或者说你这个模型的预估分在融合公式里权重（alpha beta那些）很小，有一种验证方式就是把这个模型反转掉，看看对dac gmv有没啥影响
+ 涨幅不够：这个和具体场景有关，例如a场景按以往的经验，可能离线auc+0.1%，在线就能+0.3%的gmv，那你的模型如果离线只涨了0.02%，在线肯定不会有收益的；而b场景的经验可能是，你离线auc涨0.05%，在线就能有0.5%的gmv收益。


